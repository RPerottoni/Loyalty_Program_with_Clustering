{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All in One Place: High Value Customer Identification\n",
    "\n",
    "**All in one place** is an online retail store that sells second-hand products from various brands at lower prices. With just over a year of operation, the marketing team noticed that some customers from their base purchase more expensive products more frequently, contributing significantly to the company's revenue.\n",
    "\n",
    "Based on this insight, the **marketing team** decided to **launch a loyalty program** for the **top customers** in their base, named Insiders.\n",
    "Moreover, the Marketing teams lacks the necessary knowledge to identify the customers to join the program. As a result, this task have been assigned to the company's data team, whose should develop a solution and a report to respond the marketing queries below.\n",
    "Who are the eligible individuals to participate in the program?\n",
    "How many customers will be part of the group?\n",
    "What are the main characteristics of these customers?\n",
    "What percentage of the revenue comes from the selected group?\n",
    "\n",
    "The company's data team, in accordance with the company's marketing team had combined that, as a first solution, they will use a RFM Matrix to identify the customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:54:01.013180Z",
     "start_time": "2024-11-03T18:54:00.074090Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Maniputalion and Data Analysis\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import pandas                as pd\n",
    "import numpy                 as np\n",
    "import seaborn               as sns\n",
    "import plotly.express        as px\n",
    "import plotly.graph_objects  as go\n",
    "import matplotlib.cm         as cm\n",
    "import matplotlib            as mpl\n",
    "\n",
    "from plotly.offline          import iplot\n",
    "from matplotlib              import pyplot          as plt\n",
    "\n",
    "\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 - Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:56:00.951173Z",
     "start_time": "2024-11-03T18:56:00.896916Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_and_rename_duplicate_columns(df):\n",
    "    \"\"\"\n",
    "    Remove duplicate columns resulting from a merge and renames columns to remove the '_x' suffix.\n",
    "    Removes rows related to canceled or returned invoices: where the value of the `invoice_status_y` column is equal to 'True'.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame resulting from a merge with possible duplicate columns.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with duplicate columns removed and renamed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Checks if the 'invoice_status_y' column exists and filters where the value is True\n",
    "    if 'invoice_cancelled_y' in df.columns:\n",
    "        df = df[~df['invoice_cancelled_y'].fillna(False)]\n",
    "    \n",
    "    # Identifies columns with '_x' and '_y' suffixes after the merge\n",
    "    duplicate_columns = [col for col in df.columns if col.endswith('_x') or col.endswith('_y')]\n",
    "    \n",
    "    # Creates a mapping to keep only one occurrence and rename columns\n",
    "    cols_to_keep = {}\n",
    "    for col in duplicate_columns:\n",
    "        base_name = col[:-2]  # Removes the '_x' or '_y' suffix\n",
    "        if base_name not in cols_to_keep:\n",
    "            # Saves the column with the '_x' suffix to keep and rename\n",
    "            cols_to_keep[base_name] = col\n",
    "\n",
    "    # Defines the columns to drop, keeping only one of each duplicate pair\n",
    "    cols_to_drop = set(duplicate_columns) - set(cols_to_keep.values())\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Renames the remaining columns, removing the '_x' suffix\n",
    "    df = df.rename(columns={old_name: base_name for base_name, old_name in cols_to_keep.items()})\n",
    "\n",
    "    # Filters the columns, removing invoice_cancelled\n",
    "    cols = ['invoice_no', 'stock_code', 'description', 'quantity', 'invoice_date','unit_price', 'customer_id', 'country']\n",
    "\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# 1 - DATA MANIPULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:54:15.642693Z",
     "start_time": "2024-11-03T18:54:14.736771Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/Ecommerce.csv\")\n",
    "\n",
    "# drop extra column\n",
    "df = df.drop( columns=['Unnamed: 8'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:24:35.763524Z",
     "start_time": "2024-11-03T18:24:35.727327Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 - Rename Columns to snake case pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:24:36.693405Z",
     "start_time": "2024-11-03T18:24:36.659470Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:24:37.145086Z",
     "start_time": "2024-11-03T18:24:37.138694Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_new = ['invoice_no','stock_code','description','quantity','invoice_date','unit_price','customer_id','country']\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 - Data Dimesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:24:37.577627Z",
     "start_time": "2024-11-03T18:24:37.556519Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of columns: {}'.format( df1.shape[1] ) )\n",
    "print('Number of rows: {}'.format( df1.shape[0] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 - Checking NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:26.113891Z",
     "start_time": "2024-11-03T18:25:25.458510Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3.1 - Handling NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:26.301478Z",
     "start_time": "2024-11-03T18:25:26.217304Z"
    }
   },
   "outputs": [],
   "source": [
    "# To analyse the data, two new data set are being created:\n",
    "df_missing = df1.loc[df1['customer_id'].isna(), :] # Contains the data with missing customer_id\n",
    "df_not_missing = df1.loc[~df1['customer_id'].isna(),:] # Contain the data with customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:26.915242Z",
     "start_time": "2024-11-03T18:25:26.432280Z"
    }
   },
   "outputs": [],
   "source": [
    "df_not_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:27.152182Z",
     "start_time": "2024-11-03T18:25:26.918241Z"
    }
   },
   "outputs": [],
   "source": [
    "df_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:27.214988Z",
     "start_time": "2024-11-03T18:25:27.154004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identifying which are the invoices without customer id\n",
    "missing_invoice = df_missing['invoice_no'].drop_duplicates().tolist()\n",
    "\n",
    "# Locate the missing customer_id data by searching from invoice_no\n",
    "df_aux = df_not_missing.loc[df_not_missing['invoice_no'].isin(missing_invoice)]\n",
    "\n",
    "# Print result if any\n",
    "df_aux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:27.261972Z",
     "start_time": "2024-11-03T18:25:27.221974Z"
    }
   },
   "outputs": [],
   "source": [
    "# The analysis will continue with the data set without NaN values\n",
    "df1 = df_not_missing.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 - Checkin data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:27.573871Z",
     "start_time": "2024-11-03T18:25:27.560996Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:27.856367Z",
     "start_time": "2024-11-03T18:25:27.738822Z"
    }
   },
   "outputs": [],
   "source": [
    "df1[ 'invoice_date'] = pd.to_datetime( df1['invoice_date'], format='%d-%b-%y') # changing the data on the column invoice data to match the correct data type\n",
    "\n",
    "df1['customer_id'] = df1['customer_id'].astype( int ) # changing the data on the column customer id data to match the correct data type\n",
    "\n",
    "df1['country'] = df1['country'].astype( str ) # Changing data type from object to string\n",
    "\n",
    "df1['quantity'] = df1['quantity'].astype( float ) # Changing data type from object to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 - Checking Duplicated Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5.226 duplicated registers on the data set. Are these a legit acquisition or a duplicated register of one unique sale?\n",
    "\n",
    "**Assumptions:** I will assume that it is a duplicated register and these will be removed from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:28.603892Z",
     "start_time": "2024-11-03T18:25:28.234960Z"
    }
   },
   "outputs": [],
   "source": [
    "n_duplicated = df1.duplicated().sum()\n",
    "print(f'There are {n_duplicated} duplicated registers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:29.298343Z",
     "start_time": "2024-11-03T18:25:28.606888Z"
    }
   },
   "outputs": [],
   "source": [
    "# Counting duplicate occurrences and adding the count as a new feature.\n",
    "aux = df1.value_counts().reset_index()\n",
    "\n",
    "# Creation of new dataset containing only the duplicated registers\n",
    "df_duplicated = aux.loc[aux['count']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:29.770148Z",
     "start_time": "2024-11-03T18:25:29.331145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the size of the data set with duplicated values\n",
    "aux_b= len(df1)\n",
    "\n",
    "# Drop Duplicate\n",
    "df1 = df1.drop_duplicates().reset_index()\n",
    "\n",
    "# Calculate the size of the data set after remove the duplicated values\n",
    "aux_a = len(df1)\n",
    "\n",
    "n_removed = aux_b - aux_a\n",
    "print(f'Total of {n_removed} removed from the data set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTS:**\n",
    "\n",
    "Registers with missing descriptions also lack a customer_id;\n",
    "\n",
    "To address this issue, the following actions could be considered:\n",
    "\n",
    "1. Since a unique combination of customer_id and invoice_no can include multiple entries (as granularity is defined by stock_code), compare the invoice_no from the dataset with missing values against the complete dataset and fill in the missing customer_id where matches are found;\n",
    "   \n",
    "2. Assign a random number to these customers to avoid data loss;\n",
    "\n",
    "3. Drop entries with NaN values.\n",
    "\n",
    "I conducted a test based on approach (1), but it was not possible to locate any customer_id and as the goal is to cluster customers, entries without a valid customer_id will be excluded from the analysis.\n",
    "\n",
    "Consequently, 135.080 registers will be removed, as they lack proper identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable Name | Role       | Type         | Description                                                                                          | Units     |\n",
    "|---------------|------------|--------------|------------------------------------------------------------------------------------------------------|-----------|\n",
    "| InvoiceNo     | ID         | Categorical  | A 6-digit integral number uniquely assigned to each transaction. If this code starts with 'C', it indicates a cancellation. | -         |\n",
    "| StockCode     | ID         | Categorical  | A 5-digit integral number uniquely assigned to each distinct product.                                | -         |\n",
    "| Description   | Feature    | Categorical  | Product name                                                                                        | -         |\n",
    "| Quantity      | Feature    | Integer      | The quantities of each product (item) per transaction                                               | -         |\n",
    "| InvoiceDate   | Feature    | Date         | The day and time when each transaction was generated                                                | -         |\n",
    "| UnitPrice     | Feature    | Continuous   | Product price per unit                                                                              | Sterling  |\n",
    "| CustomerID    | Feature    | Categorical  | A 5-digit integral number uniquely assigned to each customer                                        | -         |\n",
    "| Country       | Feature    | Categorical  | The name of the country where each customer resides                                                 | -         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:29.881796Z",
     "start_time": "2024-11-03T18:25:29.774164Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:25:30.463895Z",
     "start_time": "2024-11-03T18:25:30.142706Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.describe(include='object').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENTS**\n",
    "\n",
    "**1. QUANTITY**\n",
    "\n",
    "Approximately 75% of the 401603 orders contain a maximum of 12 items. The mean and standard deviation appear to be impacted by high values.\n",
    "\n",
    "**2. UNIT PRICE**\n",
    "\n",
    "The products appear to be relatively inexpensive, with an average price of 3.47. Additionally, 75% of the 401603 entries have prices below 3.75. The standard deviation is quite high indicating the presence of outliers, also the max value of this feature confirms that, where one item cost nearly 40.000 pounds.\n",
    "\n",
    "**3. INVOICE NO**\n",
    "\n",
    "There are 22,190 unique invoice numbers, indicating that the e-commerce platform processed 22,190 transactions during the period from 29/11/2016 to 08/07/2017. Additionally, invoice number 576339 contains 542 entries.\n",
    "\n",
    "**4. STOCK CODE**\n",
    "\n",
    "There are 3,684 unique products sold, with product 85123A leading as the top item by transaction volume.\n",
    "\n",
    "**5. DESCRIPTION**\n",
    "\n",
    "There are 3,896 unique descriptions compared to 3,684 unique stock codes, suggesting that some products may have multiple descriptions associated with the same stock code.\n",
    "\n",
    "**6. COUNTRY**\n",
    "\n",
    "The transactions span 37 different countries, with the majority originating from the UK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 - Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1.1 - Quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Negative numbers**: These values for quantity refers to orders that have been canceled.\n",
    "\n",
    "**High Concentration of quantity close to 0**: From the first chart it's possible to see that most of sales are of small quantity of products. And there is a specific quantity that is the preferrably one, where the sum of products sold which that quantity is more that 500.000.\n",
    "Then, I have created a new data set containing the registers where the quantity range vary from 0 to 20 and then I have identified that most of the sales are  made of 12 items.\n",
    "\n",
    "**Assumptions**: As the objective is to select a group of customers, the best customers, then I will void all purchases that were cancelled. This filter will be added in the section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:26:11.779431Z",
     "start_time": "2024-11-03T18:25:32.668759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ploting a distribution chart for quantity\n",
    "fig = px.histogram(df1, x=\"quantity\", y='quantity',\n",
    "                   marginal=\"violin\")\n",
    "                   #hover_data=df1.columns)\n",
    "\n",
    "fig.update_layout(title='Quantity Distribution',\n",
    "                  title_x=0.5,\n",
    "                  yaxis_title=\"Quantity\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the chart above we can see that most of the registers has a quantity close to 0. I will then, select data between a smaller interval and analyse it, just because there is one specific quantity amout that come to my attentido due the hight volum of it sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:26:43.114166Z",
     "start_time": "2024-11-03T18:26:11.784438Z"
    }
   },
   "outputs": [],
   "source": [
    "aux = df1.loc[ (df1['quantity'] > 0) & (df1['quantity'] < 20)]\n",
    "\n",
    "fig = px.histogram(aux, x=\"quantity\", y='quantity',\n",
    "                   marginal=\"violin\")\n",
    "                   #hover_data=df1.columns)\n",
    "\n",
    "fig.update_layout(title='Quantity Distribution',\n",
    "                  title_x=0.5,\n",
    "                  yaxis_title=\"Quantity\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:26:43.207785Z",
     "start_time": "2024-11-03T18:26:43.117698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Looking into the 5 highest register by quantity\n",
    "df1.nlargest(5, 'quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:26:43.317067Z",
     "start_time": "2024-11-03T18:26:43.258086Z"
    }
   },
   "outputs": [],
   "source": [
    "# Looking into the 5 smallest register by quantity\n",
    "df1.nsmallest(5, 'quantity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1.2 - Unit Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most products are cheap: costing less than 5.000 pounds.\n",
    "\n",
    "**There are products with high value**: As previously seem, 75% of the products costs less than 4 pounds. However the standard deviation is high and the max value is nealry 40.000. What should be further investigated\n",
    "\n",
    "**There are products where the prices is equal to 0**: These entry shall be removed from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:00:15.348951Z",
     "start_time": "2024-11-02T21:59:21.243128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ploting a distribution chart for unit price\n",
    "\n",
    "fig = px.histogram(df1, x=\"unit_price\", y='unit_price',\n",
    "                   marginal=\"violin\",\n",
    "                   hover_data=df1.columns)\n",
    "\n",
    "fig.update_layout(title='Unit Price Distribution',\n",
    "                  title_x=0.5,\n",
    "                  yaxis_title=\"Quantity\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T19:23:47.110231Z",
     "start_time": "2024-11-02T19:23:47.031111Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.nlargest(5, 'unit_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order with a high prices refers to a cancelation, I will investigate it to understand if it is an error, the unit_price of this item is correct, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T19:36:34.140161Z",
     "start_time": "2024-11-02T19:36:34.110625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's find the purchase order that originate the cancelation register\n",
    "\n",
    "df1[df1['customer_id']==15098]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upon reviewing the records for the customer who canceled the item, I observed the following:**\n",
    "\n",
    "One item has multiple descriptions: In my understanding, this is an error and should be corrected.\n",
    "\n",
    "Customer 15098 made five transactions related to the same item, with two of these transactions canceled. Below is the customer's transaction history:\n",
    "\n",
    "| index  | invoice_no | stock_code | description                  | quantity | invoice_date | unit_price | customer_id | country        |\n",
    "|--------|------------|------------|------------------------------|----------|--------------|------------|-------------|----------------|\n",
    "| 222670 | 556442     | 22502      | PICNIC BASKET WICKER SMALL   | 60       | 2017-06-08   | 4.95       | 15098       | United Kingdom |\n",
    "| 222680 | 556444     | 22502      | PICNIC BASKET WICKER 60 PIECES | 60     | 2017-06-08   | 649.50     | 15098       | United Kingdom |\n",
    "| 222681 | C556445    | M          | Manual                       | -1       | 2017-06-08   | 38970.00   | 15098       | United Kingdom |\n",
    "| 222682 | 556446     | 22502      | PICNIC BASKET WICKER 60 PIECES | 1      | 2017-06-08   | 649.50     | 15098       | United Kingdom |\n",
    "| 222692 | C556448    | 22502      | PICNIC BASKET WICKER SMALL   | -60      | 2017-06-08   | 4.95       | 15098       | United Kingdom |\n",
    "\n",
    "\n",
    "Based on this analysis, I conclude:\n",
    "\n",
    "Invoice_no 556442 was canceled, and the product was returned through invoice_no C556448.\n",
    "\n",
    "Invoice_no 556444 was canceled, and the product was returned through the manual entry invoice_no C556445.\n",
    "\n",
    "The record to be retained for analysis is the one associated with invoice_no 556446."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:08:40.003122Z",
     "start_time": "2024-11-02T21:08:39.964411Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.nsmallest(5, 'unit_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1.3 - Stock Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While analysing the data, it come to attention some stcock_code that does not reffers to products. A filter will be added, aiming to:\n",
    "\n",
    "POST - Remove. It seems to be a delivery price. Need's to be confirmed with the company;\n",
    "\n",
    "M    - Keep. It seems to be manual insertions and legit acquisition;\n",
    "\n",
    "C2   - Remove. It seems to be a delivery price. Need's to be confirmed with the company;\n",
    "\n",
    "D    - Remove. It is a discount applied on some acquisitions;\n",
    "\n",
    "DOT  - Remove. It seems to be a delivery price. Need's to be confirmed with the company;\n",
    "\n",
    "CRUK - Remove. It seems to be kind of comission.\n",
    "\n",
    "PADS - Remove. Need's to be confirmed\n",
    "\n",
    "BANK CHARGES - Remove. Bank fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:11:55.132879Z",
     "start_time": "2024-11-02T21:11:54.695800Z"
    }
   },
   "outputs": [],
   "source": [
    "df1[\"length_sc\"] = df1[\"stock_code\"].str.strip().str.len()\n",
    "\n",
    "df1[\"length_sc\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:11:55.179111Z",
     "start_time": "2024-11-02T21:11:55.139878Z"
    }
   },
   "outputs": [],
   "source": [
    "df1[df1[\"length_sc\"] < 5][\"stock_code\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:11:55.211119Z",
     "start_time": "2024-11-02T21:11:55.182108Z"
    }
   },
   "outputs": [],
   "source": [
    "df1[df1[\"length_sc\"] > 6][\"stock_code\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1.4 - Country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 345 registers where it is not possible to identify the country where the customer is from; Howevere these registers will be kept\n",
    "once still is possible to identify the customer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:11:57.066179Z",
     "start_time": "2024-11-02T21:11:57.008695Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['country'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:11:57.831592Z",
     "start_time": "2024-11-02T21:11:57.766936Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many registers does not specify the country?\n",
    "\n",
    "dfc_aux = df1[['country', 'customer_id']].groupby('country').count().reset_index()\n",
    "dfc_aux = dfc_aux.sort_values(by='customer_id', ascending=False).reset_index(drop=True)\n",
    "dfc_aux[dfc_aux['country'].isin(['Unspecified', 'European Community'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2 - DATA FILTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T21:37:19.118577Z",
     "start_time": "2023-09-19T21:37:19.087318Z"
    },
    "hidden": true
   },
   "source": [
    "As previously observed, there are some data preparation to be done. This process will be done by filtering the unecessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:10.055913Z",
     "start_time": "2024-11-02T22:45:10.019273Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Making a copy of the dataframe, just in case something goes wrong I do not need to reset the kernel and run everything again.\n",
    "df2 = df1.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['customer_id']==15098]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:11.739031Z",
     "start_time": "2024-11-02T22:45:10.261161Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# REMOVING REGISTERS WHERE THE PURCHASE HAVE BEEN RETURNED OR CANCELLED\n",
    "# Classifying each invoice as cancelled (True) or not (False) \n",
    "df2['invoice_cancelled'] = df2['invoice_no'].str.startswith(\"C\") & (df2['quantity']<0)\n",
    "\n",
    "# Separting two datasets:\n",
    "df2_canceled = df2[df2['invoice_cancelled']] # invoices cancelled\n",
    "df2_ncanceled = df2[~df2['invoice_cancelled']] # invoices not cancelled\n",
    "\n",
    "# Mergin the above two data set\n",
    "merged_df = df2_ncanceled.merge(df2_canceled, on=['stock_code','unit_price','customer_id'], how='left')\n",
    "\n",
    "# Applying function to clean the new data set by removing columns etc.\n",
    "df2 = drop_and_rename_duplicate_columns(merged_df)\n",
    "\n",
    "# Removing the register from customer 15098 which had some issues with his purchases and after an analysis some manual registers where\n",
    "# located and this is creating an outlier.\n",
    "df2 = df2.drop(df2.index[146375]).reset_index(drop=True)\n",
    "\n",
    "# # --- NUMERICAL ATTRIBUTES ---\n",
    "\n",
    "# # Filtering products where price is equal to 0\n",
    "df2 = df2.loc[df2['unit_price'] > 0, :]\n",
    "\n",
    "# --- CATEGORICAL ATTRIBUTES ---\n",
    "\n",
    "# Filtering stock_codes that does not reffers to items\n",
    "df2 = df2[~df2['stock_code'].isin( ['POST','C2','DOT','PADS','BANK CHARGES'] )]\n",
    "\n",
    "# Description\n",
    "df2 = df2.drop( columns='description', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 2.1 - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I will re-do some analysis, just to confirm that the above filteres are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:21.034246Z",
     "start_time": "2024-11-02T22:45:20.771581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2.1.1 - Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:38:09.038151Z",
     "start_time": "2024-11-02T21:37:29.758292Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Ploting a distribution chart for quantity\n",
    "\n",
    "fig = px.histogram(df2, x=\"quantity\", y='quantity',\n",
    "                   marginal=\"violin\",\n",
    "                   hover_data=df2.columns)\n",
    "\n",
    "fig.update_layout(title='Quantity Distribution',\n",
    "                  title_x=0.5,\n",
    "                  yaxis_title=\"Quantity\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:38:09.131572Z",
     "start_time": "2024-11-02T21:38:09.045193Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.nlargest(5,'quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:38:09.192166Z",
     "start_time": "2024-11-02T21:38:09.137609Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.nsmallest(5,'quantity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2.1.2 - Unit Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:07:42.618120Z",
     "start_time": "2024-11-02T22:07:04.043288Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Ploting a distribution chart for unit price\n",
    "\n",
    "fig = px.histogram(df2, x=\"unit_price\", y='unit_price',\n",
    "                   marginal=\"violin\",\n",
    "                   hover_data=df2.columns)\n",
    "\n",
    "fig.update_layout(title='Unit Price Distribution',\n",
    "                  title_x=0.5,\n",
    "                  yaxis_title=\"Quantity\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:38:48.864693Z",
     "start_time": "2024-11-02T21:38:48.792234Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2.nsmallest(5,'unit_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2.1.3 - Stock Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:14.479891Z",
     "start_time": "2024-11-02T21:30:14.438344Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:14.796183Z",
     "start_time": "2024-11-02T21:30:14.482884Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux[\"length_sc\"] = aux[\"stock_code\"].str.strip().str.len()\n",
    "\n",
    "aux[\"length_sc\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create some features that will help to get more insights and also to create a cluster of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:26.608318Z",
     "start_time": "2024-11-02T22:45:26.585272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Another copy of the dataset just run from here if something goes wrong ahead\n",
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:27.026182Z",
     "start_time": "2024-11-02T22:45:26.998449Z"
    }
   },
   "outputs": [],
   "source": [
    "# data reference\n",
    "df_ref = df3.drop( ['invoice_no','stock_code','quantity','invoice_date','unit_price','country'],axis=1).drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T21:37:38.589488Z",
     "start_time": "2023-09-13T21:37:38.580232Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## 3.1 - Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:27.724156Z",
     "start_time": "2024-11-02T22:45:27.666595Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculus of the monetary value sold\n",
    "df3.loc[:,'gross_revenue'] = df3.loc[:,'quantity'] * df3.loc[:,'unit_price']\n",
    "df_sold = df3.loc[:, ['customer_id', 'gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "\n",
    "df_ref = pd.merge( df_ref, df_sold, on='customer_id', how='left')\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:28.267589Z",
     "start_time": "2024-11-02T22:45:28.257052Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ref.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T21:38:23.932851Z",
     "start_time": "2023-09-13T21:38:23.919854Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## 3.2 - Recency - Day from last purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:35.516306Z",
     "start_time": "2024-11-02T22:45:35.455067Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Recency\n",
    "df_recency = df3.loc[:, ['customer_id', 'invoice_date']].groupby('customer_id').max().reset_index()\n",
    "df_recency['recency_days'] = (df3['invoice_date'].max() - df_recency['invoice_date']).dt.days\n",
    "df_recency = df_recency[['customer_id','recency_days']].copy()\n",
    "df_ref = pd.merge( df_ref, df_recency, on='customer_id', how='left')\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:35.877873Z",
     "start_time": "2024-11-02T22:45:35.850364Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3.3 - Qty of purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:36.523501Z",
     "start_time": "2024-11-02T22:45:36.411206Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_freq = (df3.loc[:, ['customer_id', 'invoice_no']].drop_duplicates()\n",
    "                                                    .groupby('customer_id')\n",
    "                                                    .count()\n",
    "                                                    .reset_index()\n",
    "                                                    .rename( columns={'invoice_no':'qty_invoices'}) )\n",
    "                \n",
    "df_ref = pd.merge(df_ref, df_freq, on='customer_id', how='left')\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:36.600947Z",
     "start_time": "2024-11-02T22:45:36.581940Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3.4 Qty of products purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:37.052764Z",
     "start_time": "2024-11-02T22:45:37.000246Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Number of products\n",
    "df_freqp = (df3.loc[:,['customer_id', 'quantity']].groupby('customer_id')\n",
    "                                                   .sum().reset_index()\n",
    "                                                   .rename( columns={'quantity':'qty_prod_purchased'}) )\n",
    "\n",
    "df_ref = pd.merge(df_ref, df_freqp, on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:37.177971Z",
     "start_time": "2024-11-02T22:45:37.160457Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3.5 - Range of Products per Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:37.614932Z",
     "start_time": "2024-11-02T22:45:37.496087Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_prod = ( df3.loc[:,['customer_id', 'stock_code']].groupby('customer_id')\n",
    "                                                    .count()\n",
    "                                                    .reset_index()\n",
    "                                                    .rename( columns={'stock_code':'range_of_products'}) )\n",
    "            \n",
    "df_ref = pd.merge(df_ref, df_prod, on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3.6 - Average Ticket Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:38.693921Z",
     "start_time": "2024-11-02T22:45:38.647532Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Avg Ticket\n",
    "df_avg_ticket = ( df3.loc[:, ['customer_id','gross_revenue']].groupby('customer_id')\n",
    "                                                             .mean()\n",
    "                                                             .reset_index()\n",
    "                                                             .rename( columns={'gross_revenue':'avg_ticket'}) )\n",
    "\n",
    "df_ref = pd.merge( df_ref, df_avg_ticket, on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3.7 - Frequency of Purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:45:42.703074Z",
     "start_time": "2024-11-02T22:45:40.166491Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2_max = df3[['customer_id','invoice_date']].drop_duplicates().groupby('customer_id').max().reset_index() # finding the last date of purchase per customer\n",
    "df2_min = df3[['customer_id','invoice_date']].drop_duplicates().groupby('customer_id').min().reset_index() # finding the last date of purchase per customer\n",
    "\n",
    "df_aux = ( df3[['customer_id','invoice_no','invoice_date']].drop_duplicates()\n",
    "                                                           .groupby('customer_id')\n",
    "                                                           .agg( max_ =('invoice_date', 'max'),\n",
    "                                                                 min_ =('invoice_date', 'min'),\n",
    "                                                                 days_=('invoice_date', lambda x:( (x.max() - x.min() ).days)+1),\n",
    "                                                                 buy_ =('invoice_no', 'count'))).reset_index()\n",
    "\n",
    "# Frequency\n",
    "df_aux['frequency'] = df_aux[['buy_', 'days_']].apply( lambda x: x['buy_'] / x['days_'] if x['days_'] != 0 else 0, axis=1 )\n",
    "\n",
    "# Merge\n",
    "df_ref = pd.merge(df_ref, df_aux[['customer_id','frequency']], on='customer_id', how='left')\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3.8 - Invoice Canceled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:46:02.991332Z",
     "start_time": "2024-11-02T22:46:02.959605Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Number of returns\n",
    "df_returns = df2_canceled[['customer_id','quantity']].groupby('customer_id').sum().reset_index().rename( columns={'quantity':'qty_returns'})\n",
    "df_returns['qty_returns'] = df_returns['qty_returns'] * -1\n",
    "\n",
    "df_ref = pd.merge( df_ref, df_returns, on='customer_id', how='left')\n",
    "df_ref.loc[df_ref['qty_returns'].isna(), 'qty_returns'] = 0\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3.9 - Qty avg of producst per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:46:14.324877Z",
     "start_time": "2024-11-02T22:46:14.297987Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ref['avg_qty_products_purchased'] = df_ref['qty_prod_purchased'] / df_ref['qty_invoices']\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3.10 - Week day most frequent per customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The day of the week with Monday=0, Sunday=6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:46:24.523239Z",
     "start_time": "2024-11-02T22:46:14.901686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Retrieving the week day for the specific date\n",
    "df3['week_day']= df3['invoice_date'].dt.dayofweek\n",
    "\n",
    "# Creating the dataframe with day_week per invoice_no\n",
    "aux_02 = df3[['invoice_no','customer_id','week_day']].drop_duplicates(ignore_index=True)\n",
    "\n",
    "# Calculus of week day most frequent\n",
    "aux_03 = aux_02[['customer_id', 'week_day']].groupby('customer_id').apply(lambda x: x.mode().iloc[0]).reset_index(drop=True)\n",
    "\n",
    "# Adding the new feature into the data set\n",
    "df_ref = pd.merge( df_ref, aux_03, on='customer_id', how='left')\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 - Month most frequent per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:46:33.679682Z",
     "start_time": "2024-11-02T22:46:24.533229Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieving the week day for the specific date\n",
    "df3['month']= df3['invoice_date'].dt.month\n",
    "\n",
    "# Creating the dataframe with day_week per invoice_no\n",
    "aux_312 = df3[['invoice_no','customer_id','month']].drop_duplicates(ignore_index=True)\n",
    "\n",
    "# Calculus of week day most frequent\n",
    "aux_3123 = aux_312[['customer_id', 'month']].groupby('customer_id').apply(lambda x: x.mode().iloc[0]).reset_index(drop=True)\n",
    "\n",
    "# Adding the new feature into the data set\n",
    "df_ref = pd.merge( df_ref, aux_3123, on='customer_id', how='left')\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 - Year week per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:46:34.843612Z",
     "start_time": "2024-11-02T22:46:33.682791Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieving the week day for the specific date\n",
    "df3['year_week'] = df3['invoice_date'].apply(lambda x: x.isocalendar()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4 - EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, the data is have been prepared and it is ready for an exploratory data analysis. Let's get some insights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:40:45.097463Z",
     "start_time": "2024-11-02T21:40:45.073477Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4 = df_ref.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:40:45.113450Z",
     "start_time": "2024-11-02T21:40:45.106453Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df4 = df_ref.dropna()\n",
    "# df4.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.1 - Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Metrics to be checked out:\n",
    "\n",
    "1. Cluster coesos - separados\n",
    "2. Metrics:\n",
    "    - Min, Max, Range (dispersion)\n",
    "    - Mean and Median\n",
    "    - Standard Deviation and Variance\n",
    "    - CV (Coefficient of Variation)\n",
    "    - Distribuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:40:45.159629Z",
     "start_time": "2024-11-02T21:40:45.120449Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:40:45.238308Z",
     "start_time": "2024-11-02T21:40:45.166592Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:35.535974Z",
     "start_time": "2024-11-02T21:30:35.526004Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prof = ProfileReport(df4)\n",
    "# prof.to_file('data_descriptive.html') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.2 - Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:35.551984Z",
     "start_time": "2024-11-02T21:30:35.541988Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# cols = ['customer_id']\n",
    "# df42 = df4.drop( cols, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:35.567439Z",
     "start_time": "2024-11-02T21:30:35.557995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plt.figure( figsize=(12, 15) )\n",
    "# sns.pairplot( df4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Who are the 20 customers that have spent the most money with the company?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:35.629905Z",
     "start_time": "2024-11-02T21:30:35.571436Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Group customers by 'customer_id' and calculate the total sum of 'gross_revenue.\n",
    "aux = df4.groupby('customer_id')['gross_revenue'].sum().reset_index()\n",
    "\n",
    "# Sort values in descending order by 'gross_revenue.'\n",
    "aux = aux.sort_values(by='gross_revenue', ascending=False).head(20)\n",
    "\n",
    "# Graph Definition\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=aux['customer_id'].astype(str), \n",
    "           y=aux['gross_revenue'],\n",
    "           marker={'color': aux['gross_revenue'],\n",
    "                   'colorscale': 'viridis'})])\n",
    "\n",
    "# DESIGN\n",
    "fig.update_traces(texttemplate='£%{y:.3s}', textposition='outside', cliponaxis=False)\n",
    "fig.update_layout(title='Customer With Highest Total Purchase Amount',\n",
    "                  title_x=0.5,\n",
    "                  xaxis_title=\"Customer\",\n",
    "                  yaxis_title=\"Amount Sum\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Who are the 20 customers that made the most purchases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:35.659915Z",
     "start_time": "2024-11-02T21:30:35.634907Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Group 'customer_id' and sort values in descending order by 'invoice_no'\n",
    "aux = df4[['customer_id','qty_invoices']].sort_values(by='qty_invoices', ascending=False).head(20)\n",
    "\n",
    "# Graph Definition\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=aux['customer_id'].astype(str), \n",
    "           y=aux['qty_invoices'],\n",
    "           marker={'color': aux['qty_invoices'],\n",
    "                   'colorscale': 'viridis'})])\n",
    "\n",
    "# DESIGN\n",
    "fig.update_traces(texttemplate='%{y:.3s}',textposition='outside', cliponaxis=False)\n",
    "fig.update_layout(title='Customer With Highest Qty of Invoices',\n",
    "                  title_x=0.5,\n",
    "                  xaxis_title=\"Customer\",\n",
    "                  yaxis_title=\"Amount Sum\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Who are the 20 customers with the highest number of returns or canceled orders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:35.707688Z",
     "start_time": "2024-11-02T21:30:35.662893Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Group data by 'customer_id' and calculate the total sum of 'invoice_no'\n",
    "aux = df2_ncanceled[['invoice_no','customer_id']].drop_duplicates()\n",
    "aux01 = aux[['customer_id','invoice_no']].groupby('customer_id').count().reset_index()\n",
    "\n",
    "# Sort values in decending order by qty of invoice no.\n",
    "aux01 = aux01.sort_values(by='invoice_no', ascending=False).head(20)\n",
    "\n",
    "# Graph Definition\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=aux01['customer_id'].astype(str), \n",
    "           y=aux01['invoice_no'],\n",
    "           marker={'color': aux01['invoice_no'],\n",
    "                   'colorscale': 'viridis'})])\n",
    "\n",
    "# DESIGN\n",
    "fig.update_traces(texttemplate='%{y:.3s}',textposition='outside', cliponaxis=False)\n",
    "fig.update_layout(title='Customer With Highest Qty of Invoices Cancelled',\n",
    "                  title_x=0.5,\n",
    "                  xaxis_title=\"Customer\",\n",
    "                  yaxis_title=\"Amount Sum\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### What are the 20 worst-selling items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:35.817071Z",
     "start_time": "2024-11-02T21:30:35.711442Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Group data by stock_code and calculate the total sum of quantity\n",
    "aux = df2[['stock_code','quantity']].groupby('stock_code').sum().reset_index()\n",
    "\n",
    "# Sort values in ascending order by quantity\n",
    "aux = aux.sort_values(by='quantity', ascending=True).head(20)\n",
    "\n",
    "# Graph Definition\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=aux['stock_code'].astype(str), \n",
    "           y=aux['quantity'],\n",
    "           marker={'color': aux['quantity'],\n",
    "                   'colorscale': 'viridis'})])\n",
    "\n",
    "# DESIGN\n",
    "fig.update_traces(texttemplate='%{y:.3s}',textposition='outside', cliponaxis=False)\n",
    "fig.update_layout(title='20 Worst-selling Items',\n",
    "                  title_x=0.5,\n",
    "                  xaxis_title=\"Stock Code\",\n",
    "                  yaxis_title=\"Amount Sum\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### What are the 20 best-sellings items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:35.910834Z",
     "start_time": "2024-11-02T21:30:35.821072Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Group\n",
    "aux = df2[['stock_code','quantity']].groupby('stock_code').sum().reset_index()\n",
    "aux = aux.sort_values(by='quantity', ascending=False).head(20)\n",
    "\n",
    "# Graph Definition\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=aux['stock_code'].astype(str), \n",
    "           y=aux['quantity'],\n",
    "           marker={'color': aux['quantity'],\n",
    "                   'colorscale': 'viridis'})])\n",
    "\n",
    "# DESIGN\n",
    "fig.update_traces(texttemplate='%{y:.3s}',textposition='outside', cliponaxis=False)\n",
    "fig.update_layout(title='20 Best-selling Items',\n",
    "                  title_x=0.5,\n",
    "                  xaxis_title=\"Stock Code\",\n",
    "                  yaxis_title=\"Amount Sum\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Which country have sold more by quantity of invoices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:35.988378Z",
     "start_time": "2024-11-02T21:30:35.915201Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dataset containing unique invoice no\n",
    "aux = df2.drop_duplicates(subset='invoice_no')\n",
    "aux = aux[['country','invoice_no']].groupby('country').count().reset_index()\n",
    "aux = aux.sort_values(by='invoice_no', ascending=False).head(20)\n",
    "\n",
    "# Graph Definition\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=aux['country'].astype(str), \n",
    "           y=aux['invoice_no'],\n",
    "           marker={'color': aux['invoice_no'],\n",
    "                   'colorscale': 'viridis'})])\n",
    "\n",
    "# DESIGN\n",
    "fig.update_traces(texttemplate='%{y:.3s}',textposition='outside', cliponaxis=False)\n",
    "fig.update_layout(title='Top Countries by qty of invoices',\n",
    "                  title_x=0.5,\n",
    "                  xaxis_title=\"Stock Code\",\n",
    "                  yaxis_title=\"Amount Sum\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Which country have sold more by revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:36.096627Z",
     "start_time": "2024-11-02T21:30:35.994377Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculus of the data\n",
    "aux = df3[['country','gross_revenue']].groupby('country').sum().reset_index()\n",
    "aux = aux[['country','gross_revenue']].sort_values(by='gross_revenue', ascending=False).head(20)\n",
    "\n",
    "# Graph Definition\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=aux['country'].astype(str), \n",
    "           y=aux['gross_revenue'],\n",
    "           marker={'color': aux['gross_revenue'],\n",
    "                   'colorscale': 'viridis'})])\n",
    "\n",
    "# DESIGN\n",
    "fig.update_traces(texttemplate='£%{y:.3s}',textposition='outside', cliponaxis=False)\n",
    "fig.update_layout(title='20 Best-selling Countries by Revenue',\n",
    "                  title_x=0.5,\n",
    "                  xaxis_title=\"Stock Code\",\n",
    "                  yaxis_title=\"Amount Sum\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Which week day has the highest sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:36.174625Z",
     "start_time": "2024-11-02T21:30:36.104580Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The day of the week with Monday=0, Sunday=6.\n",
    "# Group data by week_day and calculate the total sum of gross_revenue\n",
    "aux = df3[['week_day','gross_revenue']].groupby('week_day').sum().reset_index()\n",
    "\n",
    "# Graph Definition\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=aux['week_day'].astype(str), \n",
    "           y=aux['gross_revenue'],\n",
    "           marker={'color': aux['gross_revenue'],\n",
    "                   'colorscale': 'viridis'})])\n",
    "\n",
    "# DESIGN\n",
    "fig.update_traces(texttemplate='£%{y:.3s}',textposition='outside', cliponaxis=False)\n",
    "fig.update_layout(title='Sum of Gross Revenue by Day of the Week',\n",
    "                  title_x=0.5,\n",
    "                  xaxis_title=\"Stock Code\",\n",
    "                  yaxis_title=\"Amount Sum\",\n",
    "                  plot_bgcolor='white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Which month has the highest sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T21:30:41.786236Z",
     "start_time": "2024-11-02T21:30:36.182153Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Retrieve the year and month of each register\n",
    "aux = df3.copy()\n",
    "aux['y_month'] = aux['invoice_date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Group data by year_month and calculate the total sum of gross_revenue\n",
    "aux01 = aux[['y_month','gross_revenue']].groupby('y_month')['gross_revenue'].sum().reset_index()\n",
    "\n",
    "# Graph Definition\n",
    "fig = px.line(aux01, x='y_month', y='gross_revenue', title='Gross Revenue Over Month')\n",
    "\n",
    "# Graph Design\n",
    "fig.update_traces(mode='lines',  # Adiciona marcadores aos pontos de dados\n",
    "                  texttemplate='£%{y:.2f}',  # Formatação de texto para os valores\n",
    "                  textposition='top center')  # Posição do texto\n",
    "\n",
    "# Update Layout\n",
    "fig.update_layout(title_x=0.5,  # Centraliza o título\n",
    "                  xaxis_title='Month',  # Título do eixo X\n",
    "                  yaxis_title='Gross Revenue (£)',  # Título do eixo Y\n",
    "                  plot_bgcolor='white')  # Cor de fundo do gráfico\n",
    "\n",
    "# Plot Graph\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T22:47:40.602233Z",
     "start_time": "2024-11-02T22:47:23.543168Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Graph Definition\n",
    "fig = px.line(df3, x='invoice_date', y='gross_revenue', title='Gross Revenue Over Time')\n",
    "\n",
    "# Graph Design\n",
    "fig.update_traces(mode='lines',  # Adiciona marcadores aos pontos de dados\n",
    "                  texttemplate='£%{y:.2f}',  # Formatação de texto para os valores\n",
    "                  textposition='top center')  # Posição do texto\n",
    "\n",
    "# Update Chart Layout\n",
    "fig.update_layout(title_x=0.5,  # Centraliza o título\n",
    "                  xaxis_title='Invoice Date',  # Título do eixo X\n",
    "                  yaxis_title='Gross Revenue (£)',  # Título do eixo Y\n",
    "                  plot_bgcolor='white')  # Cor de fundo do gráfico\n",
    "\n",
    "# Plot chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
